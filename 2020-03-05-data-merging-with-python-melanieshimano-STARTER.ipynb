{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Datasets with Baltimore City Open Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Excel, we used the `VLOOKUP` function to combine data in different workbooks or sheets based on shared ID column data in neighboring rows. To do this, we wrote the function: \n",
    "```\n",
    "=VLOOKUP(cell in old dataset that matches a value in the first column of new dataset, \n",
    "        selected data table of new dataset, \n",
    "        row number of new data to add to old dataset, \n",
    "        exact match (0) OR approximate match (1))\n",
    "```\n",
    "which allowed us to add a column of data from *new dataset* to *old dataset* based on some shared/linking data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is super helpful and time efficient if we want to combine or condense information from different data sources our outputs, however, we're limited in the number of data columns we can transfer at a time (one) and how our final dataset appears (for example, if we want to only keep data that's in both sheets, we need to add an extra step of filtering out the null cells in the post-VLOOKUP spreadsheet. We can use **pandas merge** function to combine larger datasets in a similar way in Python, but with broader functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Pandas Merge](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.merge.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas merge allows us to merge two pandas dataframes together using the following convention: \n",
    "\n",
    "```\n",
    "merged_df = pd.merge(left_df, \n",
    "                    right_df, \n",
    "                    how='inner', \n",
    "                    on=None, \n",
    "                    left_on=None, \n",
    "                    right_on=None, \n",
    "                    left_index=False, \n",
    "                    right_index=False, \n",
    "                    sort=False, \n",
    "                    suffixes=('_x', '_y'), \n",
    "                    copy=True, \n",
    "                    indicator=False, \n",
    "                    validate=None)\n",
    "```\n",
    "where we'll mostly need to be concerned with: \n",
    "\n",
    " - __merged_df__ is the newly defined dataframe from the merged data\n",
    " - __pd__ is because we're using a pandas function\n",
    " - __merge__ is the pandas function that we're using to merge the dataframes\n",
    " - __left_df__ is the name of the dataframe that's our designated \"left\" dataframe\n",
    " - __right_df__ is the name of the dataframe that's our designated \"right\" dataframee\n",
    " - __how__ tells our dataframe how we want to merge the data (more details below)\n",
    " - __left_on__ is the name of the column that contains our \"matching data\" in the left dataframe\n",
    " - __right_on__ is the name of the column that contains our \"matching data\" in the right dataframe\n",
    " - __on__ is what we can use to define the column that contains our \"matching data\" is the column name is the same in both dataframes\n",
    "\n",
    "The rest of these values are the default merge functions (defined [here](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.merge.html)), most of which we won't often need to tweak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes to Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Excel, we can only transer data from one dataset to another, but in Python, we can merge all of the information from both datasets together, if we want. To merge our data, we'll identify the left and right data frame based on what data we want to merge onto existing data. \n",
    "\n",
    "For example, if we want to only merge a few columns from dataset df_A onto dataset df_B, we'll want to define df_B as the left dataframe and df_A as the right dataframe because we want to keep all of the data from df_B and add on some columns from df_A. However, we we want to merge all of the columns from df_A and df_B, then it doesn't really matter which dataframe we define as the left and right dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Merging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike in Excel, we can merge our data in in many different variations through the merge parameter in the merge function depending on how we define our right and left dataframes. In general, we can merge our left and right dataframes in the following ways:\n",
    " - __\"left\"__ merges data from the right dataframe onto the left dataframe *only if* if has a key that matches values in the left dataframe and fills in \"NaN\" (null) values in rows that don't have a value in the key column from the right dataframe\n",
    " - __\"right\"__ merges data from the left dataframe onto the right dataframe *only if* if has a key that matches values in the right dataframe and fills in \"NaN\" (null) values in rows that don't have a value in the key column from the left dataframe\n",
    " - __\"outer\"__ merges together and all of the data in both dataframes on the key column and fills in an \"NaN\" value for the columns and rows that don't have values or matches in the key column\n",
    " - __\"inner\"__ merges together only data that's in *both* dataframes\n",
    " \n",
    "To get a better idea of what this means, we'll run through some examples of dataframe mergine with [Baltimore City 911 Call data](https://data.baltimorecity.gov/Public-Safety/911-Police-Calls-for-Service/xviu-ezkt), [Baltimore Victim Crime Data](https://data.baltimorecity.gov/Public-Safety/BPD-Part-1-Victim-Based-Crime-Data/wsfq-mvij), and [Baltimore City Police Department Arrest Data](https://data.baltimorecity.gov/Public-Safety/BPD-Arrests/3i3v-ibrt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages for data analysis and visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bpd arrest data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview arrest data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import baltimore city 911 call data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview 911 data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import victim crime data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview crime data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our datasets we have a lot of information about arrests, crime, and 911 calls in Baltimore. Let's say that we want to aggregate all of this to look at the number of 911 calls, arrests, and crimes happening every year. \n",
    "\n",
    "To do this, we'll first need to aggregate our dataframes to count the number of occurrances per year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data types for each of our datasets (911)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_arrest info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df crime info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert columns to datetime datatype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that none of our datasets have our date or time values as datasets, so we'll need to convert them to datetime formats similar to our work last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in the arrest data with both of the date and time data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrest date time column to a datetime data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column in the crime dataset with both the date and time data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert crime date time column into a datetime datatype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the format of our datetime object in the 911 call data because we have an AM/PM string in the date time value. We also need to do this if our datetime string that we want to convert into a datetime object is in any format other than `month/date/year 24hour:min:second`\n",
    "\n",
    "A full list of the formatting for datetime is listed [here](https://www.programiz.com/python-programming/datetime/strftime). Our 911 data's CallDateTime column lists values like `11/02/2016 04:46:00 PM`, so we'll need to define our datetime column with: \n",
    "\n",
    " - __%m__ for month\n",
    " - __%d__ for day\n",
    " - __%Y__ for 4-digit year\n",
    " - __%I__ for 12-hour clock\n",
    " - __%M__ for minute\n",
    " - __%S__ for second\n",
    " - __%p__ for am/pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 911 date time column into a datetime datatype (since the values are already together in one column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look the `df.info()` all of the date time datatypes should be datetime datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Aggregation by Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's aggregate the counts of each of our datatypes by the year by first creating a \"year\" column in each of our dataframes, then using the pandas groupby function to aggregate the counts of each dataset per year. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either do this one at a time for each of our datasets similar to what we've done before, however, since we're using the dt.year function for all three datasets, we can take advantage of a python __for loop__ to do this with a little less code using the following convention: \n",
    "```\n",
    "for __value__ in __range or list__:\n",
    "    *do some action*\n",
    "```\n",
    "Which will allow us to perform the same action to whatever we've defined in the list. We want to add a \"year\" column to each of our dataframes by calling the same df.year function on the DateTime column, so we can make a list of the dataframes and tell our loop to create a new column based on the DateTime column for each dataframe. Note that this works since all of the date time columns are named the same \"DateTime\" name. If they weren't, we would need to rename the columns to make this for loop work.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write: \n",
    "\n",
    "```\n",
    "for df in df_list:\n",
    "    df[\"year\"] = df[\"DateTime\"].dt.year\n",
    "```\n",
    "\n",
    "Where the __df__ is a placeholder that we've defined as a variable for the df in our repeating action. This can be anything as long as it's consistent and the same in the functions within the for loop. __df_list__ is the list we defined with all of our dataframes.\n",
    "\n",
    "Essentially what we're saying is that for each value in our df_lists, plug in each list value any time you see a \"df\" and perform the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a for loop to add a year column to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so if we preview the crime data now, we see the year column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can aggregate the counts by year. We'll do this individually for this round since all of the columns that we want to count are named different things. \n",
    "\n",
    "Since we're combining all of this data at the end, we'll also want to rename our column data to specify which counts are in that column by defining the column name in the `.agg` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate counts of 911 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate counts of crime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate counts of arrests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally merge all of our data into one dataframe that merges the counts of crime, 911, and arrest data into one dataframe.\n",
    "\n",
    "If we look at the length of each dataframe, we can see that some of the datasets have data for more years than other datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of crime year counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of 911 call year counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of arrest year counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the crime count has the most years listed, we'll merge the arrest and crime counts onto the crime count dataframe with the `df.merge` function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the 911 call counts onto the crime count dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview tail data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the arrest count onto the merged df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have useable data for 2014-2019, we'll filter our merged dataframe to only include those rows    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe based on values in the year column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a line plot to look at the changes of all of these over time. Since our data isn't formatted how we need it (all x values in one column and all y values in another column), we'll need to use the pandas `melt` function to rearrange our data in a format that works with plotly express."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new \"melted dataframe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview melted dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use this data to make aa line graph of changes over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view line graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll export our crime, 911 call, and arrest datasets since we've cleaned them a bit (to use in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export crime as a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export 911 call as a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export arrest as a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
